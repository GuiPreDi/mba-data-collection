# ğŸ—ï¸ Data Lake - Arquitetura Medallion com MinIO e Spark

Este repositÃ³rio implementa uma **arquitetura de Data Lake em camadas** (Medallion Architecture: Bronze â†’ Silver), utilizando **Python, PySpark, MinIO (S3-compatible)** e **PostgreSQL** como fonte de dados.

O pipeline estÃ¡ dividido em etapas modulares, iniciando pela criaÃ§Ã£o da infraestrutura de buckets no MinIO e seguindo com extraÃ§Ãµes, transformaÃ§Ãµes e publicaÃ§Ãµes em camadas refinadas.

---

## ğŸ“‚ Estrutura de DiretÃ³rios

```
.
â”œâ”€â”€ create_buckets.py          # Cria bucket e estrutura base no MinIO
â”‚
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ bronze_dbloja.py       # Extrai dados do PostgreSQL e salva Parquet particionado
â”‚   â”œâ”€â”€ bronze_ibge.py         # Consome API pÃºblica (IBGE) e salva JSON no MinIO
â”‚   â””â”€â”€ bronze_json.py         # Faz upload em lote de arquivos JSON locais
â”‚
â””â”€â”€ silver/
    â”œâ”€â”€ silver_dbloja.py       # Converte Parquets da Bronze (db_loja) para Silver com tipos refinados
    â”œâ”€â”€ silver_ibge.py         # Converte JSON (API IBGE) em Parquet estruturado
    â””â”€â”€ silver_json.py         # Normaliza mÃºltiplos JSONs de uma loja (pedidos, produtos, etc.)
```

---

## ğŸ§± Arquitetura Medallion

O projeto segue a arquitetura de camadas **Bronze â†’ Silver**, onde:

| Camada | FunÃ§Ã£o | Fonte / Destino |
|--------|---------|----------------|
| **Bronze** | Captura dados crus e histÃ³ricos de mÃºltiplas origens (APIs, bancos, arquivos). | PostgreSQL, APIs REST, JSON locais â†’ MinIO (`bronze/`) |
| **Silver** | Processa, normaliza e estrutura os dados, aplicando casts, flatten e deduplicaÃ§Ã£o. | MinIO (`bronze/`) â†’ MinIO (`silver/`) via Spark |

---

## âš™ï¸ 1. CriaÃ§Ã£o de Buckets

**Script:** `create_buckets.py`

Este script conecta ao MinIO e cria os buckets e diretÃ³rios necessÃ¡rios para o pipeline:

- Bucket padrÃ£o: `datalake`
- Estrutura inicial criada:
  ```
  bronze/
  silver/
  ```
  
Uso:

```bash
python create_buckets.py
```

---

## ğŸª£ 2. Camada Bronze

### ğŸ§© a) PostgreSQL â†’ Bronze (`bronze_dbloja.py`)

Extrai tabelas de um schema PostgreSQL (`db_loja`) e salva como arquivos **Parquet particionados por data** no MinIO.  
HÃ¡ suporte a **cargas incrementais**, controladas por um arquivo JSON de metadados (`data_atualizacao.json`).

**Fluxo:**
1. LÃª tabelas via `SQLAlchemy`.
2. Verifica o timestamp da Ãºltima execuÃ§Ã£o no MinIO.
3. Extrai dados novos e salva em `bronze/dbloja/<tabela>/data=YYYYMMDD/arquivo.parquet`.
4. Atualiza o JSON de controle.

---

### ğŸŒ b) API â†’ Bronze (`bronze_ibge.py`)

Consome a **API pÃºblica do IBGE** via `BrasilAPI` e armazena a resposta JSON bruta no MinIO.  
Cada execuÃ§Ã£o gera uma partiÃ§Ã£o nova (`data=YYYYMMDD`).

```bash
python bronze_ibge.py
```

---

### ğŸ“ c) JSON Local â†’ Bronze (`bronze_json.py`)

Realiza o upload de todos os arquivos `.json` encontrados no diretÃ³rio local `/workspace/json` para o MinIO.  
Cria partiÃ§Ãµes por data automaticamente no formato:

```
bronze/json/<nome_arquivo>/data=YYYYMMDD/<nome_arquivo>_YYYYMMDD_HHMMSS.json
```

---

## ğŸ’ 3. Camada Silver

A camada **Silver** utiliza **PySpark** para ler dados da Bronze, aplicar *schema enforcement*, conversÃµes e normalizaÃ§Ãµes, e salvar versÃµes refinadas no MinIO.

---

### ğŸ¬ a) Silver DB Loja (`silver_dbloja.py`)

Processa os Parquets do schema `db_loja` da Bronze e gera versÃµes estruturadas com casts e validaÃ§Ãµes.

**Principais funcionalidades:**
- Leitura e inferÃªncia de schema fixo para cada tabela (`cliente`, `pedido`, `produto`, etc.).
- ConversÃ£o de colunas `LongType` para `TimestampType` e `DoubleType` para `DecimalType`.
- Escrita consolidada (1 arquivo) e upload para `silver/dbloja/<tabela>/`.

---

### ğŸ—ºï¸ b) Silver IBGE (`silver_ibge.py`)

Transforma o JSON mais recente do dataset IBGE em um Parquet tabular.

**Etapas:**
1. Localiza o JSON mais recente em `bronze/api/data=YYYYMMDD/`.
2. LÃª via Spark (`option("multiline", "true")`).
3. Extrai e tipa colunas (`id`, `sigla`, `regiao_id`, etc.`).
4. Remove marcadores `_SUCCESS` e realiza upload limpo para `silver/ibge_uf/`.

---

### ğŸ›’ c) Silver JSON Loja (`silver_json.py`)

Normaliza e estrutura diversos tipos de JSONs de uma loja fictÃ­cia:

- **dados_extrato** â†’ `silver/json/transacoes/`
- **dados_pedidos** â†’ `silver/json/pedidos_externos/` e `silver/json/pedidos_externos_itens/`
- **dados_produtos** â†’ `silver/json/produtos_parceiros/`
- **dados_tags** â†’ `silver/json/tags_produtos/`

Cada tipo de arquivo passa por uma rotina especÃ­fica de *flatten*, *explode* e *cast*, gerando Parquets organizados por tema.

---

## ğŸ§° DependÃªncias

Crie um ambiente virtual e instale os pacotes necessÃ¡rios:

```bash
pip install pyspark==3.5.0 pandas sqlalchemy==2.0.31 psycopg2-binary minio requests pyarrow
```

---

## ğŸ³ ExecuÃ§Ã£o no Docker / Dev Container

O projeto Ã© compatÃ­vel com ambientes baseados em **Docker Compose** contendo os serviÃ§os:

- `minio` â†’ Object Storage (porta 9000)
- `db` â†’ PostgreSQL
- `spark` â†’ Container local para execuÃ§Ã£o dos jobs Spark (opcional)

---

## ğŸš€ Ordem de ExecuÃ§Ã£o Recomendada

1. **CriaÃ§Ã£o de infraestrutura**
   ```bash
   python create_buckets.py
   ```

2. **Cargas Bronze**
   ```bash
   python bronze_dbloja.py
   python bronze_ibge.py
   python bronze_json.py
   ```

3. **TransformaÃ§Ãµes Silver**
   ```bash
   python silver_dbloja.py
   python silver_ibge.py
   python silver_json.py
   ```

---

## ğŸ§­ ObservaÃ§Ãµes

- Todos os scripts sÃ£o autÃ´nomos e idempotentes.
- A arquitetura pode ser estendida para camadas **Gold** e dashboards.
- Os dados ficam organizados conforme boas prÃ¡ticas de *data partitioning* e *schema enforcement*.
- A conexÃ£o com o MinIO Ã© feita via endpoint `minio:9000` (nÃ£o usar `localhost` dentro do Docker).

---

## ğŸ“Š Exemplo de Estrutura no MinIO

```
s3://datalake/
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ dbloja/
â”‚   â”‚   â”œâ”€â”€ produto/data=20251031/produto_20251031_102311.parquet
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ data=20251031/ibge-uf_20251031_103455.json
â”‚   â””â”€â”€ json/
â”‚       â”œâ”€â”€ dados_extrato/data=20251031/dados_extrato_20251031_100000.json
â”‚
â””â”€â”€ silver/
    â”œâ”€â”€ dbloja/
    â”œâ”€â”€ ibge_uf/
    â””â”€â”€ json/
        â”œâ”€â”€ transacoes/
        â”œâ”€â”€ pedidos_externos/
        â”œâ”€â”€ produtos_parceiros/
        â””â”€â”€ tags_produtos/
```

---

## ğŸ§© PrÃ³ximos Passos (ExtensÃµes Sugeridas)

- Adicionar **camada Gold** (QuickSight / Power BI).
- Integrar com **Airflow** para orquestraÃ§Ã£o.
- Implementar **Great Expectations** para validaÃ§Ã£o de qualidade.
- Adicionar **versionamento de schema** e **CI/CD (GitHub Actions)**.
